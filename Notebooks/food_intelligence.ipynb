{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import regex as re\n",
    "import nltk\n",
    "# !pip install gensim\n",
    "# !pip install spacy\n",
    "import spacy\n",
    "from spacy import lemmatizer\n",
    "import gensim\n",
    "import regex\n",
    "my_punctuation = '!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~•@'\n",
    "my_stopwords = nltk.corpus.stopwords.words('english')\n",
    "print(my_stopwords)\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemma = WordNetLemmatizer()\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        id                  asins          brand  \\\n",
      "0     AVphBRHOilAPnD_x0OrE             B00HXST15C  Simon Fischer   \n",
      "1     AVpfNFy1LJeJML434ma2  B008VT0W8C,B0092F8OJ8      McCormick   \n",
      "2     AVpgT49VLJeJML43MJEz             B00CHTWZ2S     Jolly Time   \n",
      "3     AVphYgnzLJeJML43aPp2             B002JJYNVW          Ziyad   \n",
      "4     AVpiS0bOLJeJML43kRsh             B00290W1CY    Fla-Vor-Ice   \n",
      "...                    ...                    ...            ...   \n",
      "9995  AVpfVL3ailAPnD_xZyHc  B00BHNV8N2,B06XC7GXCD       Wright's   \n",
      "9996  AVpgK5BZilAPnD_xofxu             B00HZO4YYW     Eden Foods   \n",
      "9997  AV00srHj-jtxr-f30m1M  B01FRJ0XKA,B01IV1D1VY    Happy Belly   \n",
      "9998  AVpfmY4RLJeJML43ANr-  B000PWIR7Q,B005ER1C6U         Quaker   \n",
      "9999  AVpe-j33LJeJML43zpy-             B001EO5JUC       Weetabix   \n",
      "\n",
      "                                             categories             dateAdded  \\\n",
      "0                   Grocery & Gourmet Food,Food,Grocery  2017-01-07T20:13:17Z   \n",
      "1                   Grocery & Gourmet Food,Food,Grocery  2016-02-05T21:08:01Z   \n",
      "2                        Grocery & Gourmet Food,Grocery  2014-02-18T01:51:23Z   \n",
      "3                        Grocery & Gourmet Food,grocery  2014-11-04T11:39:27Z   \n",
      "4                        Grocery & Gourmet Food,grocery  2014-02-18T02:32:12Z   \n",
      "...                                                 ...                   ...   \n",
      "9995  Barbecue,Grocery & Gourmet Food,Sauces, Gravie...  2015-11-06T02:16:34Z   \n",
      "9996  Food,Snacks, Cookies & Chips,Nuts & Trail Mixe...  2015-05-11T14:18:27Z   \n",
      "9997  Cashews,Grocery & Gourmet Food,Cooking & Bakin...  2017-07-12T02:48:32Z   \n",
      "9998  Food,Snacks, Cookies & Chips,Rice Cakes,Chips,...  2015-08-24T21:44:06Z   \n",
      "9999  Grocery,Pantry,Granola,Food,Breakfast & Cereal...  2017-01-16T15:28:42Z   \n",
      "\n",
      "               dateUpdated                              ean features.key  \\\n",
      "0     2017-06-30T16:48:02Z                      41642026706  Ingredients   \n",
      "1     2017-04-12T13:54:04Z                      52100018164  Ingredients   \n",
      "2     2017-08-07T16:32:11Z                      70670004141  Ingredients   \n",
      "3     2017-09-04T05:10:37Z                              NaN  Ingredients   \n",
      "4     2017-08-26T01:45:28Z  723,929,530,040,072,000,000,000  Ingredients   \n",
      "...                    ...                              ...          ...   \n",
      "9995  2017-09-11T20:56:25Z                      7.99475E+11  Ingredients   \n",
      "9996  2017-09-04T22:07:55Z                      24182001921  Ingredients   \n",
      "9997  2017-09-07T18:32:54Z                       8.4171E+11  Ingredients   \n",
      "9998  2017-09-18T23:01:44Z                      30000169766  Ingredients   \n",
      "9999  2017-09-17T01:24:53Z                      55712025711  Ingredients   \n",
      "\n",
      "                                         features.value         manufacturer  \\\n",
      "0           Dried Prunes,Water,Corn Syrup,Sugar,Pectin.    Sokol And Company   \n",
      "1     Salt,Sugar,Molasses (Refinery Syrup, Molasses,...  McCormick & Co, Inc   \n",
      "2     Salt, Yellow 5 Lake, Tricalcium Phosphate And ...              Reese's   \n",
      "3     Mechanically hulled seasame seeds.Allergy Info...                Ziyad   \n",
      "4                                                 FALSE          Fla-Vor-Ice   \n",
      "...                                                 ...                  ...   \n",
      "9995                water,natural hickory smoke flavor.             Wright's   \n",
      "9996  Organic Dry Roasted Almonds,Organic Tamari Soy...           Eden Foods   \n",
      "9997  Cashews, Vegetable Oil (May Contain One Or Mor...       AFS Brands LLC   \n",
      "9998  Whole Grain Brown Rice Flour,Degerminated Mill...          Quaker Oats   \n",
      "9999  Non-GMO Whole Grain Wheat,Non-GMO Whole Grain ...                Alpen   \n",
      "\n",
      "     manufacturerNumber                                               name  \\\n",
      "0                 33829              Simon Fischer Fruit Bttr Prune Lekvar   \n",
      "1       MCLANE500373852  McCORMICK GRILL MATES MOLASSES BACON SEASONING...   \n",
      "2                   NaN                                 Jolly Time Popcorn   \n",
      "3                   NaN                          Ziyad Tahini Sesame Sauce   \n",
      "4                   NaN                        Fla-Vor-Ice Plus Giant Pops   \n",
      "...                 ...                                                ...   \n",
      "9995                NaN                     Wright's Liquid Smoke - 3.5 Oz   \n",
      "9996            1418904  Eden Foods Organic Pocket Snacks - Tamari Almo...   \n",
      "9997                NaN          Happy Belly Fancy Whole Cashews, 44 Ounce   \n",
      "9998              16976  QuakerÂ® PoppedÂ® Cheddar Cheese Rice Crisps 6...   \n",
      "9999    00VRHG4A7E877BC                  Alpen All Natural Muesli Original   \n",
      "\n",
      "     sizes                              upc       weight  Unnamed: 15  \n",
      "0      NaN                      41642026706  10.6 pounds          NaN  \n",
      "1      NaN                      52100018164   3.5 ounces          NaN  \n",
      "2      NaN                      70670004141   1.8 pounds          NaN  \n",
      "3      NaN                      74265001560   1.6 pounds          NaN  \n",
      "4      NaN   72,392,952,335,072,300,000,000    18 pounds          NaN  \n",
      "...    ...                              ...          ...          ...  \n",
      "9995   NaN                      7.99475E+11   4.8 ounces          NaN  \n",
      "9996   NaN                      24182001921          NaN          NaN  \n",
      "9997   NaN  841,710,126,198,841,000,000,000   2.8 pounds          NaN  \n",
      "9998   NaN                      30000169766      4.3 lbs          NaN  \n",
      "9999   NaN                      55712025711          NaN          NaN  \n",
      "\n",
      "[10000 rows x 16 columns]\n",
      "            Id   ProductId          UserId                      ProfileName  \\\n",
      "0            1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
      "1            2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
      "2            3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
      "3            4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
      "4            5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
      "...        ...         ...             ...                              ...   \n",
      "568449  568450  B001EO7N10  A28KG5XORO54AY                 Lettie D. Carter   \n",
      "568450  568451  B003S1WTCU  A3I8AFVPEE8KI5                        R. Sawyer   \n",
      "568451  568452  B004I613EE  A121AA1GQV751Z                    pksd \"pk_007\"   \n",
      "568452  568453  B004I613EE   A3IBEVCTXKNOH          Kathy A. Welch \"katwel\"   \n",
      "568453  568454  B001LR2CU2  A3LGQPJCZVL9UC                         srfell17   \n",
      "\n",
      "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
      "0                          1                       1      5  1303862400   \n",
      "1                          0                       0      1  1346976000   \n",
      "2                          1                       1      4  1219017600   \n",
      "3                          3                       3      2  1307923200   \n",
      "4                          0                       0      5  1350777600   \n",
      "...                      ...                     ...    ...         ...   \n",
      "568449                     0                       0      5  1299628800   \n",
      "568450                     0                       0      2  1331251200   \n",
      "568451                     2                       2      5  1329782400   \n",
      "568452                     1                       1      5  1331596800   \n",
      "568453                     0                       0      5  1338422400   \n",
      "\n",
      "                                   Summary  \\\n",
      "0                    Good Quality Dog Food   \n",
      "1                        Not as Advertised   \n",
      "2                    \"Delight\" says it all   \n",
      "3                           Cough Medicine   \n",
      "4                              Great taffy   \n",
      "...                                    ...   \n",
      "568449                 Will not do without   \n",
      "568450                        disappointed   \n",
      "568451            Perfect for our maltipoo   \n",
      "568452  Favorite Training and reward treat   \n",
      "568453                         Great Honey   \n",
      "\n",
      "                                                     Text  \n",
      "0       I have bought several of the Vitality canned d...  \n",
      "1       Product arrived labeled as Jumbo Salted Peanut...  \n",
      "2       This is a confection that has been around a fe...  \n",
      "3       If you are looking for the secret ingredient i...  \n",
      "4       Great taffy at a great price.  There was a wid...  \n",
      "...                                                   ...  \n",
      "568449  Great for sesame chicken..this is a good if no...  \n",
      "568450  I'm disappointed with the flavor. The chocolat...  \n",
      "568451  These stars are small, so you can give 10-15 o...  \n",
      "568452  These are the BEST treats for training and rew...  \n",
      "568453  I am very satisfied ,product is as advertised,...  \n",
      "\n",
      "[568454 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "ingredient_df=pd.read_csv('../Dataset/ingredientsv1.csv')\n",
    "amazon_food_review_df=pd.read_csv('../Dataset/Reviews.csv')\n",
    "print(ingredient_df)\n",
    "print(amazon_food_review_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         I have bought several of the Vitality canned d...\n",
      "1         Product arrived labeled as Jumbo Salted Peanut...\n",
      "2         This is a confection that has been around a fe...\n",
      "3         If you are looking for the secret ingredient i...\n",
      "4         Great taffy at a great price.  There was a wid...\n",
      "                                ...                        \n",
      "568449    Great for sesame chicken..this is a good if no...\n",
      "568450    I'm disappointed with the flavor. The chocolat...\n",
      "568451    These stars are small, so you can give 10-15 o...\n",
      "568452    These are the BEST treats for training and rew...\n",
      "568453    I am very satisfied ,product is as advertised,...\n",
      "Name: Text, Length: 568454, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# print(amazon_food_review_df.head(1))\n",
    "# print(len(amazon_food_review_df['Summary'].unique()))\n",
    "food_review_text=amazon_food_review_df['Text']\n",
    "print(food_review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_clean_list=[]\n",
    "def clean_doc(text):\n",
    "    stop_free=' '.join([i for i in text.lower().split() if i not in my_stopwords])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in my_punctuation)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized\n",
    "\n",
    "doc_clean = [clean_doc(doc).split() for doc in food_review_text]  \n",
    "# with open('preprocessed.txt', 'w') as f:\n",
    "#     for i in doc_clean:\n",
    "#         f.write(str(i)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         [bought, several, vitality, canned, dog, food,...\n",
      "1         [product, arrived, labeled, jumbo, salted, pea...\n",
      "2         [confection, around, century, light, pillowy, ...\n",
      "3         [looking, secret, ingredient, robitussin, beli...\n",
      "4         [great, taffy, great, price, wide, assortment,...\n",
      "                                ...                        \n",
      "568449    [great, sesame, chickenthis, good, better, res...\n",
      "568450    [im, disappointed, flavor, chocolate, note, es...\n",
      "568451    [star, small, give, 1015, one, training, sessi...\n",
      "568452    [best, treat, training, rewarding, dog, good, ...\n",
      "568453    [satisfied, product, advertised, use, cereal, ...\n",
      "Name: text_token_list, Length: 568454, dtype: object\n"
     ]
    }
   ],
   "source": [
    "amazon_food_review_df['text_token_list']=doc_clean\n",
    "print(amazon_food_review_df['text_token_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>text_token_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>[bought, several, vitality, canned, dog, food,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>[product, arrived, labeled, jumbo, salted, pea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>[confection, around, century, light, pillowy, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>[looking, secret, ingredient, robitussin, beli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>[great, taffy, great, price, wide, assortment,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \\\n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...   \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...   \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...   \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...   \n",
       "\n",
       "                                     text_token_list  \n",
       "0  [bought, several, vitality, canned, dog, food,...  \n",
       "1  [product, arrived, labeled, jumbo, salted, pea...  \n",
       "2  [confection, around, century, light, pillowy, ...  \n",
       "3  [looking, secret, ingredient, robitussin, beli...  \n",
       "4  [great, taffy, great, price, wide, assortment,...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_food_review_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 1, 4, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_food_review_df['Score'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = \"Sugar is bad to consume. My sister likes to have sugar, but not my father.\"\n",
    "doc2 = \"My father spends a lot of time driving my sister around to dance practice.\"\n",
    "doc3 = \"Doctors suggest that driving may cause increased stress and blood pressure.\"\n",
    "doc4 = \"Sometimes I feel pressure to perform well at school, but my father never seems to drive my sister to do better.\"\n",
    "doc5 = \"Health experts say that Sugar is not good for your lifestyle.\"\n",
    "\n",
    "# compile documents\n",
    "doc_complete = [doc1, doc2, doc3, doc4, doc5]\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)\n",
    "lemma = WordNetLemmatizer()\n",
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_clean = [clean(doc).split() for doc in doc_complete]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['sugar', 'bad', 'consume', 'sister', 'like', 'sugar', 'father'], ['father', 'spends', 'lot', 'time', 'driving', 'sister', 'around', 'dance', 'practice'], ['doctor', 'suggest', 'driving', 'may', 'cause', 'increased', 'stress', 'blood', 'pressure'], ['sometimes', 'feel', 'pressure', 'perform', 'well', 'school', 'father', 'never', 'seems', 'drive', 'sister', 'better'], ['health', 'expert', 'say', 'sugar', 'good', 'lifestyle']]\n"
     ]
    }
   ],
   "source": [
    "print(doc_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
